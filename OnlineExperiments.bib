
@article{simmons_false-positive_2011,
	title = {False-positive psychology undisclosed flexibility in data collection and analysis allows presenting anything as significant},
	volume = {22},
	url = {http://pss.sagepub.com/content/22/11/1359.short},
	number = {11},
	urldate = {2014-04-07},
	journal = {Psychological science},
	author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
	year = {2011},
	pages = {1359–1366},
	file = {[PDF] from berkeley.edu:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/TNDWC7WS/Simmons et al. - 2011 - False-positive psychology undisclosed flexibility .pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/ZAQPZXKS/1359.html:text/html}
}

@article{fanelli_positive_2010,
	title = {{“Positive”} Results Increase Down the Hierarchy of the Sciences},
	volume = {5},
	url = {http://dx.doi.org/10.1371/journal.pone.0010068},
	doi = {10.1371/journal.pone.0010068},
	abstract = {The hypothesis of a Hierarchy of the Sciences with physical sciences at the top, social sciences at the bottom, and biological sciences in-between is nearly 200 years old. This order is intuitive and reflected in many features of academic life, but whether it reflects the “hardness” of scientific research—i.e., the extent to which research questions and results are determined by data and theories as opposed to non-cognitive factors—is controversial. This study analysed 2434 papers published in all disciplines and that declared to have tested a hypothesis. It was determined how many papers reported a “positive” (full or partial) or “negative” support for the tested hypothesis. If the hierarchy hypothesis is correct, then researchers in “softer” sciences should have fewer constraints to their conscious and unconscious biases, and therefore report more positive outcomes. Results confirmed the predictions at all levels considered: discipline, domain and methodology broadly defined. Controlling for observed differences between pure and applied disciplines, and between papers testing one or several hypotheses, the odds of reporting a positive result were around 5 times higher among papers in the disciplines of Psychology and Psychiatry and Economics and Business compared to Space Science, 2.3 times higher in the domain of social sciences compared to the physical sciences, and 3.4 times higher in studies applying behavioural and social methodologies on people compared to physical and chemical studies on non-biological material. In all comparisons, biological studies had intermediate values. These results suggest that the nature of hypotheses tested and the logical and methodological rigour employed to test them vary systematically across disciplines and fields, depending on the complexity of the subject matter and possibly other factors (e.g., a field's level of historical and/or intellectual development). On the other hand, these results support the scientific status of the social sciences against claims that they are completely subjective, by showing that, when they adopt a scientific approach to discovery, they differ from the natural sciences only by a matter of degree.},
	number = {4},
	urldate = {2014-04-07},
	journal = {{PLoS} {ONE}},
	author = {Fanelli, Daniele},
	month = apr,
	year = {2010},
	pages = {e10068},
	file = {journal.pone.0010068.pdf:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/H3GU778I/journal.pone.0010068.pdf:application/pdf;PLoS Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/FVMPUIVQ/infodoi10.1371journal.pone.html:text/html}
}

@article{dickersin_k_existence_1990,
	title = {{THe} existence of publication bias and risk factors for its occurrence},
	volume = {263},
	issn = {0098-7484},
	url = {http://dx.doi.org/10.1001/jama.1990.03440100097014},
	doi = {10.1001/jama.1990.03440100097014},
	abstract = {Publication bias is the tendency on the parts of investigators, reviewers, and editors to submit or accept manuscripts for publication based on the direction or strength of the study findings. Much of what has been learned about publication bias comes from the social sciences, less from the field of medicine. In medicine, three studies have provided direct evidence for this bias. Prevention of publication bias is important both from the scientific perspective (complete dissemination of knowledge) and from the perspective of those who combine results from a number of similar studies (meta-analysis). If treatment decisions are based on the published literature, then the literature must include all available data that is of acceptable quality. Currently, obtaining information regarding all studies undertaken in a given field is difficult, even impossible. Registration of clinical trials, and perhaps other types of studies, is the direction in which the scientific community should move.({JAMA.} 1990;263:1385-1389)},
	number = {10},
	urldate = {2014-04-07},
	journal = {{JAMA}},
	author = {{Dickersin K}},
	month = mar,
	year = {1990},
	pages = {1385--1389},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/A7T8UAV8/Dickersin K - 1990 - THe existence of publication bias and risk factors.pdf:application/pdf}
}

@article{greenwald_consequences_1975,
	title = {Consequences of prejudice against the null hypothesis.},
	volume = {82},
	url = {http://psycnet.apa.org/journals/bul/82/1/1/},
	number = {1},
	urldate = {2014-04-07},
	journal = {Psychological Bulletin},
	author = {Greenwald, Anthony G.},
	year = {1975},
	pages = {1},
	file = {[PDF] from washington.edu:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/IRENTHMC/Greenwald - 1975 - Consequences of prejudice against the null hypothe.pdf:application/pdf}
}

@article{loschiavo_reaching_2009,
	title = {Reaching the neglected 95\%.},
	url = {http://psycnet.apa.org/journals/amp/64/6/565/},
	urldate = {2014-03-25},
	author = {{LoSchiavo}, Frank M. and Shatz, Mark A.},
	year = {2009}
}

@article{arnett_neglected_2009,
	title = {The neglected 95\%, a challenge to psychology's philosophy of science.},
	url = {http://psycnet.apa.org/journals/amp/64/6/571/},
	urldate = {2014-03-25},
	author = {Arnett, Jeffrey Jensen},
	year = {2009}
}

@article{arnett_neglected_2008,
	title = {The neglected 95\%: why American psychology needs to become less American.},
	volume = {63},
	shorttitle = {The neglected 95\%},
	url = {http://psycnet.apa.org/journals/amp/63/7/602/},
	number = {7},
	urldate = {2014-03-25},
	journal = {American Psychologist},
	author = {Arnett, Jeffrey J.},
	year = {2008},
	pages = {602},
	file = {[PDF] from jeffreyarnett.com:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/UCBWJGCX/Arnett - 2008 - The neglected 95% why American psychology needs t.pdf:application/pdf}
}

@misc{_github_????,
	title = {{GitHub}},
	url = {https://github.com/},
	urldate = {2014-02-28},
	file = {GitHub:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/N3W9EG8U/github.com.html:text/html}
}

@misc{_git_????,
	title = {Git},
	url = {http://git-scm.com/},
	urldate = {2014-02-28},
	file = {Git:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/CI599SXZ/git-scm.com.html:text/html}
}

@misc{_cognilab_????,
	title = {Cognilab Technologies},
	url = {http://beta.cognilab.com/},
	urldate = {2014-02-28},
	file = {Cognilab Technologies:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/762ZZ3QI/beta.cognilab.com.html:text/html}
}

@misc{_python_????,
	title = {Python Philosophy},
	url = {http://c2.com/cgi/wiki?PythonPhilosophy},
	urldate = {2014-02-28},
	file = {Python Philosophy:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/PUJK3DGC/wiki.html:text/html}
}

@article{john_measuring_2012,
	title = {Measuring the Prevalence of Questionable Research Practices With Incentives for Truth Telling},
	volume = {23},
	issn = {0956-7976, 1467-9280},
	url = {http://pss.sagepub.com/content/23/5/524},
	doi = {10.1177/0956797611430953},
	abstract = {Cases of clear scientific misconduct have received significant media attention recently, but less flagrantly questionable research practices may be more prevalent and, ultimately, more damaging to the academic enterprise. Using an anonymous elicitation format supplemented by incentives for honest reporting, we surveyed over 2,000 psychologists about their involvement in questionable research practices. The impact of truth-telling incentives on self-admissions of questionable research practices was positive, and this impact was greater for practices that respondents judged to be less defensible. Combining three different estimation methods, we found that the percentage of respondents who have engaged in questionable practices was surprisingly high. This finding suggests that some questionable practices may constitute the prevailing research norm.},
	language = {en},
	number = {5},
	urldate = {2014-02-28},
	journal = {Psychological Science},
	author = {John, Leslie K. and Loewenstein, George and Prelec, Drazen},
	month = may,
	year = {2012},
	note = {{PMID:} 22508865},
	keywords = {disclosure, judgment, methodology, professional standards},
	pages = {524--532},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/9TG36AGV/John et al. - 2012 - Measuring the Prevalence of Questionable Research .pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/UGITPREC/524.html:text/html}
}

@article{rosenthal_file_1979,
	title = {The file drawer problem and tolerance for null results.},
	volume = {86},
	url = {http://psycnet.apa.org/journals/bul/86/3/638/},
	number = {3},
	urldate = {2014-02-28},
	journal = {Psychological bulletin},
	author = {Rosenthal, Robert},
	year = {1979},
	pages = {638},
	file = {[PDF] from colorado.edu:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/WK69R9NI/Rosenthal - 1979 - The file drawer problem and tolerance for null res.pdf:application/pdf}
}

@article{birnbaum_decision_2000,
	title = {Decision making in the lab and on the Web},
	url = {http://books.google.com/books?hl=en&lr=&id=Hrp8peu1FCAC&oi=fnd&pg=PA3&dq=Decision+Making+on+the+Internet+Birnbaum&ots=2Fqslu6ElD&sig=xl-0R3So8dtTsUe9770UCob1Pdw},
	urldate = {2014-02-28},
	journal = {Psychological experiments on the Internet},
	author = {Birnbaum, Michael H.},
	year = {2000},
	pages = {3–34},
	file = {Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/3FWQP38E/books.html:text/html}
}

@book{birnbaum_psychological_2000,
	title = {Psychological Experiments on the Internet},
	isbn = {9780080515373},
	abstract = {Until recently, most psychological research was conducted using subject samples in close proximity to the investigators--namely university undergraduates. In recent years, however, it has become possible to test people from all over the world by placing experiments on the internet. The number of people using the internet for this purpose is likely to become the main venue for subject pools in coming years. As such, learning about experiments on the internet will be of vital interest to all research {psychologists.Psychological} Experiments on the Internet is divided into three sections. Section I discusses the history of web experimentation, as well as the advantages, disadvantages, and validity of web-based psychological research. Section {II} discusses examples of web-based experiments on individual differences and cross-cultural studies. Section {III} provides readers with the necessary information and techniques for utilizing the internet in their own research designs.* Innovative topic that will capture the imagination of many readers* Includes examples of actual web based experiments},
	language = {en},
	publisher = {Academic Press},
	author = {Birnbaum, Michael H.},
	month = apr,
	year = {2000},
	keywords = {Mathematics / Probability \& Statistics / General, Psychology / Experimental Psychology, Psychology / General, Psychology / Statistics, Social Science / Statistics}
}

@article{peirce_generating_2008,
	title = {Generating stimuli for neuroscience using {PsychoPy}},
	volume = {2},
	issn = {16625196},
	url = {http://www.frontiersin.org/Journal/10.3389/neuro.11.010.2008/full},
	doi = {10.3389/neuro.11.010.2008},
	urldate = {2014-02-27},
	journal = {Frontiers in Neuroinformatics},
	author = {Peirce, Jonathan W},
	year = {2008},
	file = {fninf-02-010.pdf:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/7A7H9RQK/fninf-02-010.pdf:application/pdf}
}

@article{peirce_psychopypsychophysics_2007,
	title = {{PsychoPy—Psychophysics} software in Python},
	volume = {162},
	issn = {0165-0270},
	url = {http://www.sciencedirect.com/science/article/pii/S0165027006005772},
	doi = {10.1016/j.jneumeth.2006.11.017},
	abstract = {The vast majority of studies into visual processing are conducted using computer display technology. The current paper describes a new free suite of software tools designed to make this task easier, using the latest advances in hardware and software. {PsychoPy} is a platform-independent experimental control system written in the Python interpreted language using entirely free libraries. {PsychoPy} scripts are designed to be extremely easy to read and write, while retaining complete power for the user to customize the stimuli and environment.
Tools are provided within the package to allow everything from stimulus presentation and response collection (from a wide range of devices) to simple data analysis such as psychometric function fitting. Most importantly, {PsychoPy} is highly extensible and the whole system can evolve via user contributions. If a user wants to add support for a particular stimulus, analysis or hardware device they can look at the code for existing examples, modify them and submit the modifications back into the package so that the whole community benefits.},
	number = {1–2},
	urldate = {2014-02-27},
	journal = {Journal of Neuroscience Methods},
	author = {Peirce, Jonathan W.},
	month = may,
	year = {2007},
	keywords = {Psychometric, Psychophysics, Software, Stimulus presentation, Vision},
	pages = {8--13},
	file = {ScienceDirect Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/TJ5FMK29/Peirce - 2007 - PsychoPy—Psychophysics software in Python.pdf:application/pdf;ScienceDirect Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/4BN2DIAN/S0165027006005772.html:text/html}
}

@article{ioannidis_why_2005,
	title = {Why Most Published Research Findings Are False},
	volume = {2},
	url = {http://dx.doi.org/10.1371/journal.pmed.0020124},
	doi = {10.1371/journal.pmed.0020124},
	abstract = {Published research findings are sometimes refuted by subsequent evidence, says Ioannidis, with ensuing confusion and disappointment.},
	number = {8},
	urldate = {2014-02-27},
	journal = {{PLoS} Med},
	author = {Ioannidis, John P. A.},
	month = aug,
	year = {2005},
	pages = {e124},
	file = {PLoS Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/3945AAZH/Ioannidis - 2005 - Why Most Published Research Findings Are False.pdf:application/pdf;PLoS Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/7JKRJK4A/journal.pmed.html:text/html}
}

@article{simonsohn_p-curve:_2013,
	title = {P-Curve: A Key to the File-Drawer.},
	shorttitle = {P-Curve},
	url = {http://psycnet.apa.org/psycinfo/2013-25331-001/},
	urldate = {2014-02-26},
	author = {Simonsohn, Uri and Nelson, Leif D. and Simmons, Joseph P.},
	year = {2013},
	file = {this.pdf:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/MJBEKGKU/this.pdf:application/pdf}
}

@article{henrich_most_2010,
	title = {Most people are not {WEIRD}},
	volume = {466},
	url = {http://www.nature.com/nature/journal/v466/n7302/abs/466029a.html},
	number = {7302},
	urldate = {2014-02-24},
	journal = {Nature},
	author = {Henrich, Joseph and Heine, Steven J. and Norenzayan, Ara},
	year = {2010},
	pages = {29–29},
	file = {[PDF] from bucknell.edu:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/Z78HURZQ/Henrich et al. - 2010 - Most people are not WEIRD.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/RE8A27BI/466029a.html:text/html}
}

@article{owen_putting_2010,
	title = {Putting brain training to the test},
	volume = {465},
	url = {http://www.nature.com/nature/journal/vnfv/ncurrent/full/nature09042.html},
	number = {7299},
	urldate = {2014-02-24},
	journal = {Nature},
	author = {Owen, Adrian M. and Hampshire, Adam and Grahn, Jessica A. and Stenton, Robert and Dajani, Said and Burns, Alistair S. and Howard, Robert J. and Ballard, Clive G.},
	year = {2010},
	pages = {775–778},
	file = {323647344.pdf:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/QV68D9EE/323647344.pdf:application/pdf;[HTML] from europepmc.org:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/URCXNQA5/reload=2;jsessionid=ArA5bcKbOn67sNmmVPzI.html:text/html;[HTML] from nih.gov:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/26P7G25Z/PMC2884087.html:text/html;nature09042.pdf:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/TSATWM6N/nature09042.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/FNPHNBA8/nature09042.html:text/html;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/3D2T6X5I/nature09042.html:text/html}
}

@inproceedings{nicholas_google_2011,
	title = {Google Generation {II:} web behaviour experiments with the {BBC}},
	volume = {63},
	shorttitle = {Google Generation {II}},
	url = {http://www.emeraldinsight.com/journals.htm?articleid=1902139&show=abstract},
	urldate = {2014-02-24},
	booktitle = {Aslib Proceedings},
	publisher = {Emerald Group Publishing Limited},
	author = {Nicholas, David and Rowlands, Ian and Clark, David and Williams, Peter},
	year = {2011},
	pages = {28–45},
	file = {[PDF] from ciber-research.eu:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/5ISUQS47/Nicholas et al. - 2011 - Google Generation II web behaviour experiments wi.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/IG2B6WPX/journals.html:text/html}
}

@article{resnick_scratch:_2009,
	title = {Scratch: Programming for All},
	volume = {52},
	issn = {0001-0782},
	shorttitle = {Scratch},
	url = {http://doi.acm.org/10.1145/1592761.1592779},
	doi = {10.1145/1592761.1592779},
	abstract = {{"Digital} fluency" should mean designing, creating, and remixing, not just browsing, chatting, and interacting.},
	number = {11},
	urldate = {2014-02-14},
	journal = {Commun. {ACM}},
	author = {Resnick, Mitchel and Maloney, John and Monroy-Hernández, Andrés and Rusk, Natalie and Eastmond, Evelyn and Brennan, Karen and Millner, Amon and Rosenbaum, Eric and Silver, Jay and Silverman, Brian and Kafai, Yasmin},
	month = nov,
	year = {2009},
	pages = {60–67},
	file = {p60-resnick.pdf:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/X4TBMIS9/p60-resnick.pdf:application/pdf}
}

@article{reips_web_2000,
	title = {The Web experiment method: Advantages, disadvantages, and solutions},
	shorttitle = {The Web experiment method},
	url = {http://books.google.com/books?hl=en&lr=&id=Hrp8peu1FCAC&oi=fnd&pg=PA89&dq=The+Web+experiment+method:+Advantages,+dis-+advantages,+and+solutions.&ots=2Fqrjl3Kqz&sig=BBC3i9DiP3mZF8K1PwjpuiybB6k},
	urldate = {2014-02-13},
	journal = {Psychological experiments on the Internet},
	author = {Reips, Ulf-Dietrich},
	year = {2000},
	pages = {89–117},
	file = {[PDF] from deusto.es:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/5UPHBMM8/Reips - 2000 - The Web experiment method Advantages, disadvantag.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/JAFN78HJ/books.html:text/html}
}

@article{nosek_harvesting_2002,
	title = {Harvesting implicit group attitudes and beliefs from a demonstration web site.},
	volume = {6},
	url = {http://psycnet.apa.org/journals/gdn/6/1/101/},
	number = {1},
	urldate = {2014-02-13},
	journal = {Group Dynamics: Theory, Research, and Practice},
	author = {Nosek, Brian A. and Banaji, Mahzarin and Greenwald, Anthony G.},
	year = {2002},
	pages = {101},
	file = {[PDF] from gatech.edu:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/F5XKX4GJ/Nosek et al. - 2002 - Harvesting implicit group attitudes and beliefs fr.pdf:application/pdf}
}

@article{mcgraw_integrity_2000,
	title = {The integrity of Web-delivered experiments: Can you trust the data?},
	volume = {11},
	shorttitle = {The integrity of Web-delivered experiments},
	url = {http://pss.sagepub.com/content/11/6/502.short},
	number = {6},
	urldate = {2014-02-13},
	journal = {Psychological Science},
	author = {{McGraw}, Kenneth O. and Tew, Mark D. and Williams, John E.},
	year = {2000},
	pages = {502–506},
	file = {[PDF] from sagepub.com:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/ES88R3J5/McGraw et al. - 2000 - The integrity of Web-delivered experiments Can yo.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/7X9V3DFZ/502.html:text/html}
}

@article{kraut_psychological_2004,
	title = {Psychological research online: report of Board of Scientific Affairs' Advisory Group on the Conduct of Research on the Internet.},
	volume = {59},
	shorttitle = {Psychological research online},
	url = {http://psycnet.apa.org/journals/amp/59/2/105/},
	number = {2},
	urldate = {2014-02-13},
	journal = {American Psychologist},
	author = {Kraut, Robert and Olson, Judith and Banaji, Mahzarin and Bruckman, Amy and Cohen, Jeffrey and Couper, Mick},
	year = {2004},
	pages = {105},
	file = {[PDF] from uta.edu:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/WB8ADSMF/Kraut et al. - 2004 - Psychological research online report of Board of .pdf:application/pdf}
}

@article{krantz_comparing_1997,
	title = {Comparing the results of laboratory and World-Wide Web samples on the determinants of female attractiveness},
	volume = {29},
	url = {http://link.springer.com/article/10.3758/BF03204824},
	number = {2},
	urldate = {2014-02-13},
	journal = {Behavior Research Methods, Instruments, \& Computers},
	author = {Krantz, John H. and Ballard, Jody and Scher, Jody},
	year = {1997},
	pages = {264–269},
	file = {[PDF] from springer.com:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/JJQ66PX3/Krantz et al. - 1997 - Comparing the results of laboratory and World-Wide.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/8DBQGVPQ/BF03204824.html:text/html}
}

@article{kendler_web-based_2009,
	title = {A web-based study of personality, psychopathology and substance use in twin, other relative and relationship pairs},
	volume = {12},
	url = {http://journals.cambridge.org/abstract_S1832427400009701},
	number = {02},
	urldate = {2014-02-13},
	journal = {Twin Research and Human Genetics},
	author = {Kendler, Kenneth S. and Myers, John and Potter, Jeff and Opalesky, Jill},
	year = {2009},
	pages = {137–141},
	file = {S1832427400009701a.pdf:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/KIQCFSIZ/S1832427400009701a.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/ZD86NCRN/displayAbstract.html:text/html}
}

@article{haworth_internet_2007,
	title = {Internet cognitive testing of large samples needed in genetic research},
	volume = {10},
	url = {http://journals.cambridge.org/abstract_S1832427400008148},
	number = {04},
	urldate = {2014-02-13},
	journal = {Twin Research and Human Genetics},
	author = {Haworth, Claire and Harlaar, Nicole and Kovas, Yulia and Davis, Oliver {SP} and Oliver, Bonamy R. and Hayiou-Thomas, Marianna E. and Frances, Jane and Busfield, Patricia and {McMillan}, Andrew and Dale, Philip S.},
	year = {2007},
	pages = {554–563},
	file = {[PDF] from whiterose.ac.uk:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/N3NRVA24/Haworth et al. - 2007 - Internet cognitive testing of large samples needed.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/3MX2QD74/displayAbstract.html:text/html}
}

@article{ritter_internet_2004,
	title = {Internet versus mailed questionnaires: a randomized comparison},
	volume = {6},
	shorttitle = {Internet versus mailed questionnaires},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1550608/},
	number = {3},
	urldate = {2014-02-13},
	journal = {Journal of Medical Internet Research},
	author = {Ritter, Philip and Lorig, Kate and Laurent, Diana and Matthews, Katy},
	year = {2004},
	file = {1550608.epub:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/DI2KCZ7D/1550608.epub:application/epub+zip;[HTML] from nih.gov:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/XVIGNKZR/PMC1550608.html:text/html}
}

@article{gosling_should_2004,
	title = {Should we trust web-based studies? A comparative analysis of six preconceptions about internet questionnaires.},
	volume = {59},
	shorttitle = {Should we trust web-based studies?},
	url = {http://psycnet.apa.org/journals/amp/59/2/93/},
	number = {2},
	urldate = {2014-02-13},
	journal = {American Psychologist},
	author = {Gosling, Samuel D. and Vazire, Simine and Srivastava, Sanjay and John, Oliver P.},
	year = {2004},
	pages = {93},
	file = {[PDF] from simine.com:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/86WTIW3S/Gosling et al. - 2004 - Should we trust web-based studies A comparative a.pdf:application/pdf}
}

@article{buhrmester_amazons_2011,
	title = {Amazon's Mechanical Turk a new source of inexpensive, yet high-quality, data?},
	volume = {6},
	url = {http://pps.sagepub.com/content/6/1/3.short},
	number = {1},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Buhrmester, Michael and Kwang, Tracy and Gosling, Samuel D.},
	year = {2011},
	pages = {3–5},
	file = {[HTML] from sagepub.com:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/ABM8K8BN/3.html:text/html;Perspectives on Psychological Science-2011-Buhrmester-3-5.pdf:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/4N8PH3M3/Perspectives on Psychological Science-2011-Buhrmester-3-5.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/PHDXKF8M/3.html:text/html}
}

@article{buchanan_using_1999,
	title = {Using the Internet for psychological research: Personality testing on the World Wide Web},
	volume = {90},
	shorttitle = {Using the Internet for psychological research},
	url = {http://onlinelibrary.wiley.com/doi/10.1348/000712699161189/abstract},
	number = {1},
	urldate = {2014-02-13},
	journal = {British Journal of Psychology},
	author = {Buchanan, Tom and Smith, John L.},
	year = {1999},
	pages = {125–144},
	file = {000712699161189.pdf:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/B5F6MHIB/000712699161189.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/4QMD546H/abstract.html:text/html}
}

@article{buchanan_nonequivalence_2005,
	title = {Nonequivalence of on-line and paper-and-pencil psychological tests: The case of the prospective memory questionnaire},
	volume = {37},
	shorttitle = {Nonequivalence of on-line and paper-and-pencil psychological tests},
	url = {http://link.springer.com/article/10.3758/BF03206409},
	number = {1},
	urldate = {2014-02-13},
	journal = {Behavior Research Methods},
	author = {Buchanan, Tom and Ali, Tarick and Heffernan, Thomas M. and Ling, Jonathan and Parrott, Andrew C. and Rodgers, Jacqui and Scholey, Andrew B.},
	year = {2005},
	pages = {148–154},
	file = {[PDF] from springer.com:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/EWAXXGDI/Buchanan et al. - 2005 - Nonequivalence of on-line and paper-and-pencil psy.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/TT6RW47Q/BF03206409.html:text/html}
}

@book{joinson_oxford_2007,
	title = {Oxford handbook of internet psychology},
	url = {http://books.google.com/books?hl=en&lr=&id=zyhkAfDb_i4C&oi=fnd&pg=PR5&dq=Personality+testing+on+the+Internet:+What+we+know,+and+what+we+do+not.&ots=oac-_sduom&sig=0HuH-plNu6IisPEBijLyoR0gDf4},
	urldate = {2014-02-13},
	publisher = {Oxford University Press},
	author = {Joinson, Adam},
	year = {2007},
	file = {Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/CWGGR6TM/books.html:text/html}
}

@article{birnbaum_web-based_2001,
	title = {A Web-based program of research on decision making},
	url = {http://psych.fullerton.edu/mbirnbaum/web/dis3.pdf},
	urldate = {2014-02-13},
	journal = {Dimensions of Internet science},
	author = {Birnbaum, Michael H.},
	year = {2001},
	pages = {23–55},
	file = {[PDF] from fullerton.edu:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/F7SFZWV3/Birnbaum - 2001 - A Web-based program of research on decision making.pdf:application/pdf}
}

@article{henrich_beyond_2010,
	title = {Beyond {WEIRD:} Towards a broad-based behavioral science},
	volume = {33},
	shorttitle = {Beyond {WEIRD}},
	doi = {10.1017/S0140525X10000725},
	abstract = {In our response to the 28 (largely positive) commentaries from an esteemed collection of researchers, we (1) consolidate additional evidence, extensions, and amplifications offered by our commentators; (2) emphasize the value of integrating experimental and ethnographic methods, and show how researchers using behavioral games have done precisely this; (3) present our concerns with arguments from several commentators that separate variable “content” from “computations” or “basic processes”; (4) address concerns that the patterns we highlight marking {WEIRD} people as psychological outliers arise from aspects of the researchers and the research process; (5) respond to the claim that as members of the same species, humans must have the same invariant psychological processes; (6) address criticisms of our telescoping contrasts; and (7) return to the question of explaining why {WEIRD} people are psychologically unusual. We believe a broad-based behavioral science of human nature needs to integrate a variety of methods and apply them to diverse populations, well beyond the {WEIRD} samples it has largely relied upon.},
	number = {2-3},
	journal = {Behavioral and Brain Sciences},
	author = {Henrich, Joseph and Heine, Steven J. and Norenzayan, Ara},
	year = {2010},
	pages = {111--135},
	file = {Cambridge Journals PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/EKVPZSZ8/Henrich et al. - 2010 - Beyond WEIRD Towards a broad-based behavioral sci.pdf:application/pdf;Cambridge Journals Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/5ZCX7AAC/displayAbstract.html:text/html;Cambridge Journals Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/GRDTRG9E/displayAbstract.html:text/html}
}

@article{stroebe_alleged_2014,
	title = {The Alleged Crisis and the Illusion of Exact Replication},
	volume = {9},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/9/1/59},
	doi = {10.1177/1745691613514450},
	abstract = {There has been increasing criticism of the way psychologists conduct and analyze studies. These critiques as well as failures to replicate several high-profile studies have been used as justification to proclaim a “replication crisis” in psychology. Psychologists are encouraged to conduct more “exact” replications of published studies to assess the reproducibility of psychological research. This article argues that the alleged “crisis of replicability” is primarily due to an epistemological misunderstanding that emphasizes the phenomenon instead of its underlying mechanisms. As a consequence, a replicated phenomenon may not serve as a rigorous test of a theoretical hypothesis because identical operationalizations of variables in studies conducted at different times and with different subject populations might test different theoretical constructs. Therefore, we propose that for meaningful replications, attempts at reinstating the original circumstances are not sufficient. Instead, replicators must ascertain that conditions are realized that reflect the theoretical variable(s) manipulated (and/or measured) in the original study.},
	language = {en},
	number = {1},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Stroebe, Wolfgang and Strack, Fritz},
	month = jan,
	year = {2014},
	keywords = {critical rationalism, epistemology, null findings, Priming, replicability crisis, replication, scientific fraud},
	pages = {59--71},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/P8C7FP2B/Stroebe and Strack - 2014 - The Alleged Crisis and the Illusion of Exact Repli.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/74DN82J9/59.html:text/html}
}

@article{stroebe_scientific_2012,
	title = {Scientific Misconduct and the Myth of Self-Correction in Science},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/670},
	doi = {10.1177/1745691612460687},
	abstract = {The recent Stapel fraud case came as a shattering blow to the scientific community of psychologists and damaged both their image in the media and their collective self-esteem. The field responded with suggestions of how fraud could be prevented. However, the Stapel fraud is only one among many cases. Before basing recommendations on one case, it would be informative to study other cases to assess how these frauds were discovered. The authors analyze a convenience sample of fraud cases to see whether (social) psychology is more susceptible to fraud than other disciplines. They also evaluate whether the peer review process and replications work well in practice to detect fraud. There is no evidence that psychology is more vulnerable to fraud than the biomedical sciences, and most frauds are detected through information from whistleblowers with inside information. On the basis of this analysis, the authors suggest a number of strategies that might reduce the risk of scientific fraud.},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Stroebe, Wolfgang and Postmes, Tom and Spears, Russell},
	month = nov,
	year = {2012},
	keywords = {fraud, peer review, replication, research integrity, scientific misconduct},
	pages = {670--688},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/PT7VBU2E/Stroebe et al. - 2012 - Scientific Misconduct and the Myth of Self-Correct.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/UB3SQ5DE/670.html:text/html}
}

@article{fiedler_long_2012,
	title = {The Long Way From α-Error Control to Validity Proper Problems With a Short-Sighted False-Positive Debate},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/661},
	doi = {10.1177/1745691612462587},
	abstract = {Several influential publications have sensitized the community of behavioral scientists to the dangers of inflated effects and false-positive errors leading to the unwarranted publication of nonreplicable findings. This issue has been related to prominent cases of data fabrication and survey results pointing to bad practices in empirical science. Although we concur with the motives behind these critical arguments, we note that an isolated debate of false positives may itself be misleading and counter-productive. Instead, we argue that, given the current state of affairs in behavioral science, false negatives often constitute a more serious problem. Referring to Wason’s (1960) seminal work on inductive reasoning, we show that the failure to assertively generate and test alternative hypotheses can lead to dramatic theoretical mistakes, which cannot be corrected by any kind of rigor applied to statistical tests of the focal hypotheses. We conclude that a scientific culture rewarding strong inference (Platt, 1964) is more likely to see progress than a culture preoccupied with tightening its standards for the mere publication of original findings.},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Fiedler, Klaus and Kutzner, Florian and Krueger, Joachim I.},
	month = nov,
	year = {2012},
	keywords = {false negatives, false positives, replicability, strong inference},
	pages = {661--669},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/8QH24QW8/Fiedler et al. - 2012 - The Long Way From α-Error Control to Validity Prop.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/H9INI7QA/661.html:text/html}
}

@article{nuzzo_scientific_2014,
	title = {Scientific method: Statistical errors},
	volume = {506},
	issn = {0028-0836, 1476-4687},
	shorttitle = {Scientific method},
	url = {http://www.nature.com/doifinder/10.1038/506150a},
	doi = {10.1038/506150a},
	number = {7487},
	urldate = {2014-02-13},
	journal = {Nature},
	author = {Nuzzo, Regina},
	month = feb,
	year = {2014},
	pages = {150--152},
	file = {506150a.pdf:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/2MPZIS75/506150a.pdf:application/pdf}
}

@article{neuroskeptic_nine_2012,
	title = {The Nine Circles of Scientific Hell},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/643},
	doi = {10.1177/1745691612459519},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Neuroskeptic},
	month = nov,
	year = {2012},
	pages = {643--644},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/2HMUT7EH/Neuroskeptic - 2012 - The Nine Circles of Scientific Hell.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/VGKPZM7Q/643.html:text/html}
}

@article{ioannidis_why_2012,
	title = {Why Science Is Not Necessarily Self-Correcting},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/645},
	doi = {10.1177/1745691612464056},
	abstract = {The ability to self-correct is considered a hallmark of science. However, self-correction does not always happen to scientific evidence by default. The trajectory of scientific credibility can fluctuate over time, both for defined scientific fields and for science at-large. History suggests that major catastrophes in scientific credibility are unfortunately possible and the argument that “it is obvious that progress is made” is weak. Careful evaluation of the current status of credibility of various scientific fields is important in order to understand any credibility deficits and how one could obtain and establish more trustworthy results. Efficient and unbiased replication mechanisms are essential for maintaining high levels of scientific credibility. Depending on the types of results obtained in the discovery and replication phases, there are different paradigms of research: optimal, self-correcting, false nonreplication, and perpetuated fallacy. In the absence of replication efforts, one is left with unconfirmed (genuine) discoveries and unchallenged fallacies. In several fields of investigation, including many areas of psychological science, perpetuated and unchallenged fallacies may comprise the majority of the circulating evidence. I catalogue a number of impediments to self-correction that have been empirically studied in psychological science. Finally, I discuss some proposed solutions to promote sound replication practices enhancing the credibility of scientific results as well as some potential disadvantages of each of them. Any deviation from the principle that seeking the truth has priority over any other goals may be seriously damaging to the self-correcting functions of science.},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Ioannidis, John P. A.},
	month = nov,
	year = {2012},
	keywords = {replication, self-correction},
	pages = {645--654},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/68JT2SSK/Ioannidis - 2012 - Why Science Is Not Necessarily Self-Correcting.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/BHKBRCZ4/645.html:text/html}
}

@article{fuchs_psychologists_2012,
	title = {Psychologists Are Open to Change, yet Wary of Rules},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/639},
	doi = {10.1177/1745691612459521},
	abstract = {Psychologists must change the way they conduct and report their research—this notion has been the topic of much debate in recent years. One article recently published in Psychological Science proposing six requirements for researchers concerning data collection and reporting practices as well as four guidelines for reviewers aimed at improving the publication process has recently received much attention (Simmons, Nelson, \& Simonsohn, 2011). We surveyed 1,292 psychologists to address two questions: Do psychologists support these concrete changes to data collection, reporting, and publication practices, and if not, what are their reasons? Respondents also indicated the percentage of print and online journal space that should be dedicated to novel studies and direct replications as well as the percentage of published psychological research that they believed would be confirmed if direct replications were conducted. We found that psychologists are generally open to change. Five requirements for researchers and three guidelines for reviewers were supported as standards of good practice, whereas one requirement was even supported as a publication condition. Psychologists appear to be less in favor of mandatory conditions of publication than standards of good practice. We conclude that the proposal made by Simmons, Nelson \& Simonsohn (2011) is a starting point for such standards.},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Fuchs, Heather M. and Jenny, Mirjam and Fiedler, Susann},
	month = nov,
	year = {2012},
	keywords = {publication bias, publication practices, replication},
	pages = {639--642},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/D5IX6R2G/Fuchs et al. - 2012 - Psychologists Are Open to Change, yet Wary of Rule.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/ESENXUEP/639.html:text/html}
}

@article{wagenmakers_agenda_2012,
	title = {An Agenda for Purely Confirmatory Research},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/632},
	doi = {10.1177/1745691612463078},
	abstract = {The veracity of substantive research claims hinges on the way experimental data are collected and analyzed. In this article, we discuss an uncomfortable fact that threatens the core of psychology’s academic enterprise: almost without exception, psychologists do not commit themselves to a method of data analysis before they see the actual data. It then becomes tempting to fine tune the analysis to the data in order to obtain a desired result—a procedure that invalidates the interpretation of the common statistical tests. The extent of the fine tuning varies widely across experiments and experimenters but is almost impossible for reviewers and readers to gauge. To remedy the situation, we propose that researchers preregister their studies and indicate in advance the analyses they intend to conduct. Only these analyses deserve the label “confirmatory,” and only for these analyses are the common statistical tests valid. Other analyses can be carried out but these should be labeled “exploratory.” We illustrate our proposal with a confirmatory replication attempt of a study on extrasensory perception.},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Wagenmakers, Eric-Jan and Wetzels, Ruud and Borsboom, Denny and Maas, Han L. J. van der and Kievit, Rogier A.},
	month = nov,
	year = {2012},
	keywords = {Bayesian hypothesis test, confirmatory experiments, {ESP}, wonky statistics},
	pages = {632--638},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/SQK7FFT2/Wagenmakers et al. - 2012 - An Agenda for Purely Confirmatory Research.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/488V95AB/632.html:text/html}
}

@article{nosek_scientific_2012,
	title = {Scientific Utopia {II.} Restructuring Incentives and Practices to Promote Truth Over Publishability},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/615},
	doi = {10.1177/1745691612459058},
	abstract = {An academic scientist’s professional success depends on publishing. Publishing norms emphasize novel, positive results. As such, disciplinary incentives encourage design, analysis, and reporting decisions that elicit positive results and ignore negative results. Prior reports demonstrate how these incentives inflate the rate of false effects in published science. When incentives favor novelty over replication, false results persist in the literature unchallenged, reducing efficiency in knowledge accumulation. Previous suggestions to address this problem are unlikely to be effective. For example, a journal of negative results publishes otherwise unpublishable reports. This enshrines the low status of the journal and its content. The persistence of false findings can be meliorated with strategies that make the fundamental but abstract accuracy motive—getting it right—competitive with the more tangible and concrete incentive—getting it published. This article develops strategies for improving scientific practices and knowledge accumulation that account for ordinary human motivations and biases.},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Nosek, Brian A. and Spies, Jeffrey R. and Motyl, Matt},
	month = nov,
	year = {2012},
	keywords = {false positives, incentives, methodology, motivated reasoning, replication},
	pages = {615--631},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/TNDBD6VH/Nosek et al. - 2012 - Scientific Utopia II. Restructuring Incentives and.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/4NQGTFER/615.html:text/html}
}

@article{koole_rewarding_2012,
	title = {Rewarding Replications A Sure and Simple Way to Improve Psychological Science},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/608},
	doi = {10.1177/1745691612462586},
	abstract = {Although replications are vital to scientific progress, psychologists rarely engage in systematic replication efforts. In this article, we consider psychologists’ narrative approach to scientific publications as an underlying reason for this neglect and propose an incentive structure for replications within psychology. First, researchers need accessible outlets for publishing replications. To accomplish this, psychology journals could publish replication reports in files that are electronically linked to reports of the original research. Second, replications should get cited. This can be achieved by cociting replications along with original research reports. Third, replications should become a valued collaborative effort. This can be realized by incorporating replications in teaching programs and by stimulating adversarial collaborations. The proposed incentive structure for replications can be developed in a relatively simple and cost-effective manner. By promoting replications, this incentive structure may greatly enhance the dependability of psychology’s knowledge base.},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Koole, Sander L. and Lakens, Daniël},
	month = nov,
	year = {2012},
	keywords = {philosophy of science, publication bias, replication, scientific fraud, selective reporting},
	pages = {608--614},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/S2CWGXIR/Koole and Lakens - 2012 - Rewarding Replications A Sure and Simple Way to Im.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/2R9W7IGR/608.html:text/html}
}

@article{grahe_harnessing_2012,
	title = {Harnessing the Undiscovered Resource of Student Research Projects},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/605},
	doi = {10.1177/1745691612459057},
	abstract = {This article suggests that undergraduate research can help advance the science of psychology. We introduce a hypothetical “question-list paradigm” as a mechanism to do this. Each year, thousands of undergraduate projects are completed as part of the educational experience. Although many of these studies may not contain sufficient contributions for publication, they provide a good test of the replicability of established findings across populations at different institutions and geographic locations. Thus, these projects could meet the needs of recent calls for increased replications of psychological studies while simultaneously benefiting the student researchers, their instructors, and the field in general.},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Grahe, Jon E. and Reifman, Alan and Hermann, Anthony D. and Walker, Marie and Oleson, Kathryn C. and Nario-Redmond, Michelle and Wiebe, Richard P.},
	month = nov,
	year = {2012},
	keywords = {collective research, data collection, experimental replication, pedagogy, “question-list paradigm”, undergraduate research},
	pages = {605--607},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/CVWFXC3V/Grahe et al. - 2012 - Harnessing the Undiscovered Resource of Student Re.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/ZFZ5DBNA/605.html:text/html}
}

@article{frank_teaching_2012,
	title = {Teaching Replication},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/600},
	doi = {10.1177/1745691612460686},
	abstract = {Replication is held as the gold standard for ensuring the reliability of published scientific literature. But conducting direct replications is expensive, time-consuming, and unrewarded under current publication practices. So who will do them? The authors argue that students in laboratory classes should replicate recent findings as part of their training in experimental methods. In their own courses, the authors have found that replicating cutting-edge results is exciting and fun; it gives students the opportunity to make real scientific contributions (provided supervision is appropriate); and it provides object lessons about the scientific process, the importance of reporting standards, and the value of openness.},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Frank, Michael C. and Saxe, Rebecca},
	month = nov,
	year = {2012},
	keywords = {experimental methods, pedagogy, replication},
	pages = {600--604},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/GHMH8T43/Frank and Saxe - 2012 - Teaching Replication.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/8IK9IJPI/600.html:text/html}
}

@article{simonsohn_it_2012,
	title = {It Does Not Follow Evaluating the One-Off Publication Bias Critiques by Francis (2012a, 2012b, 2012c, 2012d, 2012e, in press)},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/597},
	doi = {10.1177/1745691612463399},
	abstract = {Francis (2012a, 2012b, 2012c, 2012d, 2012e, in press) attacks individual papers through critiques that apply faulty logic to analyses ironically biased by cherry picking. However well intentioned, the critiques are probably counterproductive to their stipulated goal and certainly unfair to the targeted authors.},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Simonsohn, Uri},
	month = nov,
	year = {2012},
	keywords = {publication bias},
	pages = {597--599},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/MPW79FQ9/Simonsohn - 2012 - It Does Not Follow Evaluating the One-Off Publicat.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/2FXKIXN6/597.html:text/html}
}

@article{galak_you_2012,
	title = {You Could Have Just Asked Reply to Francis (2012)},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/595},
	doi = {10.1177/1745691612463079},
	abstract = {In an earlier article (Galak \& Meyvis, 2011), we reported eight studies that demonstrate people’s tendency to remember unpleasant experiences as more aversive when they think they will experience them again. Based on a test that, ironically, suffers from publication bias, Francis (2012) estimated that there is a high probability that we obtained at least one unsuccessful study that was left in the file drawer. He then argues that, because of this, our findings should be discounted. We propose that, instead of engaging in a statistical fishing expedition, Francis should have simply asked us for our file drawer. If he had done so, he would have quickly realized that a meta-analysis of all our studies (both published and unpublished) shows that the effect we reported is highly reliable. We suggest that when the answer is out there, it makes more sense to ask for it than to estimate it.},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Galak, Jeff and Meyvis, Tom},
	month = nov,
	year = {2012},
	keywords = {data, file drawer, meta-analysis},
	pages = {595--596},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/9EKB5CHD/Galak and Meyvis - 2012 - You Could Have Just Asked Reply to Francis (2012).pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/PM9578CD/595.html:text/html}
}

@article{francis_psychology_2012,
	title = {The Psychology of Replication and Replication in Psychology},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/585},
	doi = {10.1177/1745691612459520},
	abstract = {Like other scientists, psychologists believe experimental replication to be the final arbiter for determining the validity of an empirical finding. Reports in psychology journals often attempt to prove the validity of a hypothesis or theory with multiple experiments that replicate a finding. Unfortunately, these efforts are sometimes misguided because in a field like experimental psychology, ever more successful replication does not necessarily ensure the validity of an empirical finding. When psychological experiments are analyzed with statistics, the rules of probability dictate that random samples should sometimes be selected that do not reject the null hypothesis, even if an effect is real. As a result, it is possible for a set of experiments to have too many successful replications. When there are too many successful replications for a given set of experiments, a skeptical scientist should be suspicious that null or negative findings have been suppressed, the experiments were run improperly, or the experiments were analyzed improperly. This article describes the implications of this observation and demonstrates how to test for too much successful replication by using a set of experiments from a recent research paper.},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Francis, Gregory},
	month = nov,
	year = {2012},
	keywords = {aversion, effect size, memory, power, publication bias, replication, scientific method},
	pages = {585--594},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/GVCMR972/Francis - 2012 - The Psychology of Replication and Replication in P.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/UUQ4VWB5/585.html:text/html}
}

@article{klein_low_2012,
	title = {Low Hopes, High Expectations Expectancy Effects and the Replicability of Behavioral Experiments},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/572},
	doi = {10.1177/1745691612463704},
	abstract = {This article revisits two classical issues in experimental methodology: experimenter bias and demand characteristics. We report a content analysis of the method section of experiments reported in two psychology journals (Psychological Science and the Journal of Personality and Social Psychology), focusing on aspects of the procedure associated with these two phenomena, such as mention of the presence of the experimenter, suspicion probing, and handling of deception. We note that such information is very often absent, which prevents observers from gauging the extent to which such factors influence the results. We consider the reasons that may explain this omission, including the automatization of psychology experiments, the evolution of research topics, and, most important, a view of research participants as passive receptacles of stimuli. Using a situated social cognition perspective, we emphasize the importance of integrating the social context of experiments in the explanation of psychological phenomena. We illustrate this argument via a controversy on stereotype-based behavioral priming effects.},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Klein, Olivier and Doyen, Stéphane and Leys, Christophe and Gama, Pedro A. Magalhães de Saldanha da and Miller, Sarah and Questienne, Laurence and Cleeremans, Axel},
	month = nov,
	year = {2012},
	keywords = {demand characteristics, expectancy, experimenter bias, methodology, replicability},
	pages = {572--584},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/D42FVPWT/Klein et al. - 2012 - Low Hopes, High Expectations Expectancy Effects an.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/N7RX2NJI/572.html:text/html}
}

@article{giner-sorolla_science_2012,
	title = {Science or Art? How Aesthetic Standards Grease the Way Through the Publication Bottleneck but Undermine Science},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	shorttitle = {Science or Art?},
	url = {http://pps.sagepub.com/content/7/6/562},
	doi = {10.1177/1745691612457576},
	abstract = {The current crisis in psychological research involves issues of fraud, replication, publication bias, and false positive results. I argue that this crisis follows the failure of widely adopted solutions to psychology’s similar crisis of the 1970s. The untouched root cause is an information-economic one: Too many studies divided by too few publication outlets equals a bottleneck. Articles cannot pass through just by showing theoretical meaning and methodological rigor; their results must appear to support the hypothesis perfectly. Consequently, psychologists must master the art of presenting perfect-looking results just to survive in the profession. This favors aesthetic criteria of presentation in a way that harms science’s search for truth. Shallow standards of statistical perfection distort analyses and undermine the accuracy of cumulative data; narrative expectations encourage dishonesty about the relationship between results and hypotheses; criteria of novelty suppress replication attempts. Concerns about truth in research are emerging in other sciences and may eventually descend on our heads in the form of difficult and insensitive regulations. I suggest a more palatable solution: to open the bottleneck, putting structures in place to reward broader forms of information sharing beyond the exquisite art of present-day journal publication.},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Giner-Sorolla, Roger},
	month = nov,
	year = {2012},
	keywords = {methodology, publishing, Statistics},
	pages = {562--571},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/M97S4PQR/Giner-Sorolla - 2012 - Science or Art How Aesthetic Standards Grease the.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/MF8WFRSF/562.html:text/html}
}

@article{ferguson_vast_2012,
	title = {A Vast Graveyard of Undead Theories Publication Bias and Psychological Science’s Aversion to the Null},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/555},
	doi = {10.1177/1745691612459059},
	abstract = {Publication bias remains a controversial issue in psychological science. The tendency of psychological science to avoid publishing null results produces a situation that limits the replicability assumption of science, as replication cannot be meaningful without the potential acknowledgment of failed replications. We argue that the field often constructs arguments to block the publication and interpretation of null results and that null results may be further extinguished through questionable researcher practices. Given that science is dependent on the process of falsification, we argue that these problems reduce psychological science’s capability to have a proper mechanism for theory falsification, thus resulting in the promulgation of numerous “undead” theories that are ideologically popular but have little basis in fact.},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Ferguson, Christopher J. and Heene, Moritz},
	month = nov,
	year = {2012},
	keywords = {fail-safe number, falsification, meta-analyses, null hypothesis significance testing, publication bias},
	pages = {555--561},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/9KQNZDAF/Ferguson and Heene - 2012 - A Vast Graveyard of Undead Theories Publication Bi.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/C7SAAXUS/555.html:text/html}
}

@article{bakker_rules_2012,
	title = {The Rules of the Game Called Psychological Science},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/543},
	doi = {10.1177/1745691612459060},
	abstract = {If science were a game, a dominant rule would probably be to collect results that are statistically significant. Several reviews of the psychological literature have shown that around 96\% of papers involving the use of null hypothesis significance testing report significant outcomes for their main results but that the typical studies are insufficiently powerful for such a track record. We explain this paradox by showing that the use of several small underpowered samples often represents a more efficient research strategy (in terms of finding p {\textless} .05) than does the use of one larger (more powerful) sample. Publication bias and the most efficient strategy lead to inflated effects and high rates of false positives, especially when researchers also resorted to questionable research practices, such as adding participants after intermediate testing. We provide simulations that highlight the severity of such biases in meta-analyses. We consider 13 meta-analyses covering 281 primary studies in various fields of psychology and find indications of biases and/or an excess of significant results in seven. These results highlight the need for sufficiently powerful replications and changes in journal policies.},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Bakker, Marjan and Dijk, Annette van and Wicherts, Jelte M.},
	month = nov,
	year = {2012},
	keywords = {false positives, power, publication bias, replication, sample size},
	pages = {543--554},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/EQWTJACV/Bakker et al. - 2012 - The Rules of the Game Called Psychological Science.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/EAFI22KU/543.html:text/html}
}

@article{makel_replications_2012,
	title = {Replications in Psychology Research How Often Do They Really Occur?},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/537},
	doi = {10.1177/1745691612460688},
	abstract = {Recent controversies in psychology have spurred conversations about the nature and quality of psychological research. One topic receiving substantial attention is the role of replication in psychological science. Using the complete publication history of the 100 psychology journals with the highest 5-year impact factors, the current article provides an overview of replications in psychological research since 1900. This investigation revealed that roughly 1.6\% of all psychology publications used the term replication in text. A more thorough analysis of 500 randomly selected articles revealed that only 68\% of articles using the term replication were actual replications, resulting in an overall replication rate of 1.07\%. Contrary to previous findings in other fields, this study found that the majority of replications in psychology journals reported similar findings to their original studies (i.e., they were successful replications). However, replications were significantly less likely to be successful when there was no overlap in authorship between the original and replicating articles. Moreover, despite numerous systemic biases, the rate at which replications are being published has increased in recent decades.},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Makel, Matthew C. and Plucker, Jonathan A. and Hegarty, Boyd},
	month = nov,
	year = {2012},
	keywords = {content analysis, replication, research methodology},
	pages = {537--542},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/BXPP7P49/Makel et al. - 2012 - Replications in Psychology Research How Often Do T.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/H3SG6XHU/537.html:text/html}
}

@article{pashler_editors_2012,
	title = {Editors’ Introduction to the Special Section on Replicability in Psychological Science A Crisis of Confidence?},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/528},
	doi = {10.1177/1745691612465253},
	language = {en},
	number = {6},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Pashler, Harold and Wagenmakers, Eric-Jan},
	month = nov,
	year = {2012},
	pages = {528--530},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/RPJXEDVU/Pashler and Wagenmakers - 2012 - Editors’ Introduction to the Special Section on Re.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/R7Q2V9UT/528.html:text/html}
}

@article{simons_value_2014,
	title = {The Value of Direct Replication},
	volume = {9},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/9/1/76},
	doi = {10.1177/1745691613514755},
	abstract = {Reproducibility is the cornerstone of science. If an effect is reliable, any competent researcher should be able to obtain it when using the same procedures with adequate statistical power. Two of the articles in this special section question the value of direct replication by other laboratories. In this commentary, I discuss the problematic implications of some of their assumptions and argue that direct replication by multiple laboratories is the only way to verify the reliability of an effect.},
	language = {en},
	number = {1},
	urldate = {2014-02-13},
	journal = {Perspectives on Psychological Science},
	author = {Simons, Daniel J.},
	month = jan,
	year = {2014},
	keywords = {conceptual replication, direct replication, generalizability, reliability},
	pages = {76--80},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/73NJVVWR/Simons - 2014 - The Value of Direct Replication.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/FNJ75XVU/76.html:text/html}
}

@article{miguel_promoting_2014,
	title = {Promoting Transparency in Social Science Research},
	volume = {343},
	issn = {0036-8075, 1095-9203},
	url = {http://www.sciencemag.org/content/343/6166/30},
	doi = {10.1126/science.1245317},
	language = {en},
	number = {6166},
	urldate = {2014-02-13},
	journal = {Science},
	author = {Miguel, E. and Camerer, C. and Casey, K. and Cohen, J. and Esterling, K. M. and Gerber, A. and Glennerster, R. and Green, D. P. and Humphreys, M. and Imbens, G. and Laitin, D. and Madon, T. and Nelson, L. and Nosek, B. A. and Petersen, M. and Sedlmayr, R. and Simmons, J. P. and Simonsohn, U. and Laan, M. Van der},
	month = jan,
	year = {2014},
	note = {{PMID:} 24385620},
	pages = {30--31},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/KVD7CJAQ/Miguel et al. - 2014 - Promoting Transparency in Social Science Research.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/WG8UIXSH/30.html:text/html}
}

@article{halberda_number_2012,
	title = {Number sense across the lifespan as revealed by a massive Internet-based sample},
	volume = {109},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/content/109/28/11116},
	doi = {10.1073/pnas.1200196109},
	abstract = {It has been difficult to determine how cognitive systems change over the grand time scale of an entire life, as few cognitive systems are well enough understood; observable in infants, adolescents, and adults; and simple enough to measure to empower comparisons across vastly different ages. Here we address this challenge with data from more than 10,000 participants ranging from 11 to 85 years of age and investigate the precision of basic numerical intuitions and their relation to students’ performance in school mathematics across the lifespan. We all share a foundational number sense that has been observed in adults, infants, and nonhuman animals, and that, in humans, is generated by neurons in the intraparietal sulcus. Individual differences in the precision of this evolutionarily ancient number sense may impact school mathematics performance in children; however, we know little of its role beyond childhood. Here we find that population trends suggest that the precision of one’s number sense improves throughout the school-age years, peaking quite late at ∼30 y. Despite this gradual developmental improvement, we find very large individual differences in number sense precision among people of the same age, and these differences relate to school mathematical performance throughout adolescence and the adult years. The large individual differences and prolonged development of number sense, paired with its consistent and specific link to mathematics ability across the age span, hold promise for the impact of educational interventions that target the number sense.},
	language = {en},
	number = {28},
	urldate = {2014-02-13},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Halberda, Justin and Ly, Ryan and Wilmer, Jeremy B. and Naiman, Daniel Q. and Germine, Laura},
	month = jul,
	year = {2012},
	note = {{PMID:} 22733748},
	keywords = {aging, analog magnitude, approximate number system, cognitive development, ensemble representation},
	pages = {11116--11120},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/E5CTDUEE/Halberda et al. - 2012 - Number sense across the lifespan as revealed by a .pdf:application/pdf;Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/D4UJA2DG/Halberda et al. - 2012 - Number sense across the lifespan as revealed by a .pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/WRSVWJFD/11116.html:text/html;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/XZBEAUWU/1200196109.html:text/html}
}

@article{germine_is_2012,
	title = {Is the Web as good as the lab? Comparable performance from Web and lab in cognitive/perceptual experiments},
	volume = {19},
	issn = {1069-9384, 1531-5320},
	shorttitle = {Is the Web as good as the lab?},
	url = {http://link.springer.com/article/10.3758/s13423-012-0296-9},
	doi = {10.3758/s13423-012-0296-9},
	abstract = {With the increasing sophistication and ubiquity of the Internet, behavioral research is on the cusp of a revolution that will do for population sampling what the computer did for stimulus control and measurement. It remains a common assumption, however, that data from self-selected Web samples must involve a trade-off between participant numbers and data quality. Concerns about data quality are heightened for performance-based cognitive and perceptual measures, particularly those that are timed or that involve complex stimuli. In experiments run with uncompensated, anonymous participants whose motivation for participation is unknown, reduced conscientiousness or lack of focus could produce results that would be difficult to interpret due to decreased overall performance, increased variability of performance, or increased measurement noise. Here, we addressed the question of data quality across a range of cognitive and perceptual tests. For three key performance metrics—mean performance, performance variance, and internal reliability—the results from self-selected Web samples did not differ systematically from those obtained from traditionally recruited and/or lab-tested samples. These findings demonstrate that collecting data from uncompensated, anonymous, unsupervised, self-selected participants need not reduce data quality, even for demanding cognitive and perceptual experiments.},
	language = {en},
	number = {5},
	urldate = {2014-02-13},
	journal = {Psychonomic Bulletin \& Review},
	author = {Germine, Laura and Nakayama, Ken and Duchaine, Bradley C. and Chabris, Christopher F. and Chatterjee, Garga and Wilmer, Jeremy B.},
	month = oct,
	year = {2012},
	keywords = {cognition, Cognitive Psychology, Face recognition, Visual perception, Web-based testing},
	pages = {847--857},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/QKR3Z5GW/Germine et al. - 2012 - Is the Web as good as the lab Comparable performa.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/3JX4CX5F/10.html:text/html}
}

@article{collaboration_open_2012,
	title = {An Open, Large-Scale, Collaborative Effort to Estimate the Reproducibility of Psychological Science},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/7/6/657},
	doi = {10.1177/1745691612462588},
	abstract = {Reproducibility is a defining feature of science. However, because of strong incentives for innovation and weak incentives for confirmation, direct replication is rarely practiced or published. The Reproducibility Project is an open, large-scale, collaborative effort to systematically examine the rate and predictors of reproducibility in psychological science. So far, 72 volunteer researchers from 41 institutions have organized to openly and transparently replicate studies published in three prominent psychological journals in 2008. Multiple methods will be used to evaluate the findings, calculate an empirical rate of replication, and investigate factors that predict reproducibility. Whatever the result, a better understanding of reproducibility will ultimately improve confidence in scientific methodology and findings.},
	language = {en},
	number = {6},
	urldate = {2014-02-12},
	journal = {Perspectives on Psychological Science},
	author = {Collaboration, Open Science},
	month = nov,
	year = {2012},
	keywords = {methodology, open, psychological science, replication, reproducibility},
	pages = {657--660},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/8SQUFN5Z/Collaboration - 2012 - An Open, Large-Scale, Collaborative Effort to Esti.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/V4BMSXVC/657.html:text/html}
}

@article{pashler_is_2012,
	title = {Is the replicability crisis overblown? Three arguments examined},
	volume = {7},
	shorttitle = {Is the replicability crisis overblown?},
	url = {http://pps.sagepub.com/content/7/6/531.short},
	number = {6},
	urldate = {2014-02-12},
	journal = {Perspectives on Psychological Science},
	author = {Pashler, Harold and Harris, Christine R.},
	year = {2012},
	pages = {531–536},
	file = {[PDF] from ucsd.edu:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/5P6J2GTJ/Pashler and Harris - 2012 - Is the replicability crisis overblown Three argum.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/9GK3WCBA/531.html:text/html}
}

@article{crump_evaluating_2013,
	title = {Evaluating Amazon's Mechanical Turk as a Tool for Experimental Behavioral Research},
	volume = {8},
	url = {http://dx.doi.org/10.1371/journal.pone.0057410},
	doi = {10.1371/journal.pone.0057410},
	abstract = {Amazon Mechanical Turk ({AMT)} is an online crowdsourcing service where anonymous online workers complete web-based tasks for small sums of money. The service has attracted attention from experimental psychologists interested in gathering human subject data more efficiently. However, relative to traditional laboratory studies, many aspects of the testing environment are not under the experimenter's control. In this paper, we attempt to empirically evaluate the fidelity of the {AMT} system for use in cognitive behavioral experiments. These types of experiment differ from simple surveys in that they require multiple trials, sustained attention from participants, comprehension of complex instructions, and millisecond accuracy for response recording and stimulus presentation. We replicate a diverse body of tasks from experimental psychology including the Stroop, Switching, Flanker, Simon, Posner Cuing, attentional blink, subliminal priming, and category learning tasks using participants recruited using {AMT.} While most of replications were qualitatively successful and validated the approach of collecting data anonymously online using a web-browser, others revealed disparity between laboratory results and online results. A number of important lessons were encountered in the process of conducting these replications that should be of value to other researchers.},
	number = {3},
	urldate = {2013-07-29},
	journal = {{PLoS} {ONE}},
	author = {Crump, Matthew J. C. and {McDonnell}, John V. and Gureckis, Todd M.},
	month = mar,
	year = {2013},
	pages = {e57410},
	file = {PLoS Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/WJBN8PZJ/Crump et al. - 2013 - Evaluating Amazon's Mechanical Turk as a Tool for .pdf:application/pdf;PLoS Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/SSU2VIGN/Crump et al. - 2013 - Evaluating Amazon's Mechanical Turk as a Tool for .html:text/html}
}

@inproceedings{taylor_simultaneous_2006,
	title = {Simultaneous localization, calibration, and tracking in an ad hoc sensor network},
	doi = {10.1109/IPSN.2006.244053},
	abstract = {We introduce simultaneous localization and tracking, called {SLAT}, the problem of tracking a target in a sensor network while simultaneously localizing and calibrating the nodes of the network. Our proposed solution, {LaSLAT}, is a Bayesian filter that provides on-line probabilistic estimates of sensor locations and target tracks. It does not require globally accessible beacon signals or accurate ranging between the nodes. Real hardware experiments are presented for {2D} and {3D}, indoor and outdoor, and ultrasound and audible ranging-hardware-based deployments. Results demonstrate rapid convergence and high positioning accuracy},
	booktitle = {The Fifth International Conference on Information Processing in Sensor Networks, 2006. {IPSN} 2006},
	author = {Taylor, C. and Rahimi, A. and Bachrach, J. and Shrobe, H. and Grue, A.},
	year = {2006},
	keywords = {ad hoc networks, ad hoc sensor network, Area measurement, Bayesian filter, Bayesian methods, Bayes methods, calibration, Filtering, filtering theory, Filters, Hardware, Intelligent networks, Intelligent sensors, {LaSLAT}, Localization, network localization, on-line probabilistic estimation, position estimation, probability, statistical machine learning, target tracking, tracking, Ultrasonic imaging, wireless sensor networks},
	pages = {27--33},
	file = {IEEE Xplore Abstract Record:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/XKN6Z2SS/abs_all.html:text/html;IEEE Xplore Abstract Record:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/SJNBQ8CC/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/693MM986/Taylor et al. - 2006 - Simultaneous localization, calibration, and tracki.pdf:application/pdf;IEEE Xplore Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/IKZ65635/Taylor et al. - 2006 - Simultaneous localization, calibration, and tracki.pdf:application/pdf}
}

@misc{_selenium_????,
	title = {Selenium - Web Browser Automation},
	url = {http://docs.seleniumhq.org/},
	urldate = {2013-05-13},
	file = {Selenium - Web Browser Automation:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/D2EWQDVT/docs.seleniumhq.org.html:text/html}
}

@article{rand_promise_2012,
	title = {The promise of Mechanical Turk: How online labor markets can help theorists run behavioral experiments},
	volume = {299},
	issn = {0022-5193},
	shorttitle = {Evolution of Cooperation},
	url = {http://www.sciencedirect.com/science/article/pii/S0022519311001330},
	doi = {10.1016/j.jtbi.2011.03.004},
	abstract = {Combining evolutionary models with behavioral experiments can generate powerful insights into the evolution of human behavior. The emergence of online labor markets such as Amazon Mechanical Turk ({AMT)} allows theorists to conduct behavioral experiments very quickly and cheaply. The process occurs entirely over the computer, and the experience is quite similar to performing a set of computer simulations. Thus {AMT} opens the world of experimentation to evolutionary theorists. In this paper, I review previous work combining theory and experiments, and I introduce online labor markets as a tool for behavioral experimentation. I review numerous replication studies indicating that {AMT} data is reliable. I also present two new experiments on the reliability of self-reported demographics. In the first, I use {IP} address logging to verify {AMT} subjects' self-reported country of residence, and find that 97\% of responses are accurate. In the second, I compare the consistency of a range of demographic variables reported by the same subjects across two different studies, and find between 81\% and 98\% agreement, depending on the variable. Finally, I discuss limitations of {AMT} and point out potential pitfalls. I hope this paper will encourage evolutionary modelers to enter the world of experimentation, and help to strengthen the bond between theoretical and empirical analyses of the evolution of human behavior.},
	urldate = {2012-12-03},
	journal = {Journal of Theoretical Biology},
	author = {Rand, David G.},
	month = apr,
	year = {2012},
	keywords = {Cooperation, Economic games, Evolutionary game theory, Experimental economics, Internet},
	pages = {172--179},
	file = {ScienceDirect Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/JIWW56K7/Rand - 2012 - The promise of Mechanical Turk How online labor m.pdf:application/pdf;ScienceDirect Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/R9C5WM7X/Rand - 2012 - The promise of Mechanical Turk How online labor m.html:text/html}
}

@article{mason_conducting_2012,
	title = {Conducting behavioral research on Amazon’s Mechanical Turk},
	volume = {44},
	issn = {1554-3528},
	url = {http://link.springer.com/article/10.3758/s13428-011-0124-6},
	doi = {10.3758/s13428-011-0124-6},
	abstract = {Amazon’s Mechanical Turk is an online labor market where requesters post jobs and workers choose which jobs to do for pay. The central purpose of this article is to demonstrate how to use this Web site for conducting behavioral research and to lower the barrier to entry for researchers who could benefit from this platform. We describe general techniques that apply to a variety of types of research and experiments across disciplines. We begin by discussing some of the advantages of doing experiments on Mechanical Turk, such as easy access to a large, stable, and diverse subject pool, the low cost of doing experiments, and faster iteration between developing theory and executing experiments. While other methods of conducting behavioral research may be comparable to or even better than Mechanical Turk on one or more of the axes outlined above, we will show that when taken as a whole Mechanical Turk can be a useful tool for many researchers. We will discuss how the behavior of workers compares with that of experts and laboratory subjects. Then we will illustrate the mechanics of putting a task on Mechanical Turk, including recruiting subjects, executing the task, and reviewing the work that was submitted. We also provide solutions to common problems that a researcher might face when executing their research on this platform, including techniques for conducting synchronous experiments, methods for ensuring high-quality work, how to keep data private, and how to maintain code security.},
	language = {en},
	number = {1},
	urldate = {2012-12-03},
	journal = {Behavior Research Methods},
	author = {Mason, Winter and Suri, Siddharth},
	month = mar,
	year = {2012},
	keywords = {Cognitive Psychology, Crowdsourcing, Mechanical turk, Online research},
	pages = {1--23},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/4PGW96BJ/Mason and Suri - 2012 - Conducting behavioral research on Amazon’s Mechani.pdf:application/pdf;Snapshot:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/IQUFZZFG/Mason and Suri - 2012 - Conducting behavioral research on Amazon’s Mechani.html:text/html}
}

@article{birnbaum_human_2004,
	title = {Human Research and Data Collection via the Internet},
	volume = {55},
	url = {http://www.annualreviews.org/doi/abs/10.1146/annurev.psych.55.090902.141601},
	doi = {10.1146/annurev.psych.55.090902.141601},
	abstract = {Advantages and disadvantages of Web and lab research are reviewed. Via the World Wide Web, one can efficiently recruit large, heterogeneous samples quickly, recruit specialized samples (people with rare characteristics), and standardize procedures, making studies easy to replicate. Alternative programming techniques (procedures for data collection) are compared, including client-side as opposed to server-side programming. Web studies have methodological problems; for example, higher rates of drop out and of repeated participation. Web studies must be thoroughly analyzed and tested before launching on-line. Many studies compared data obtained in Web versus lab. These two methods usually reach the same conclusions; however, there are significant differences between college students tested in the lab and people recruited and tested via the Internet. Reasons that Web researchers are enthusiastic about the potential of the new methods are discussed.},
	number = {1},
	urldate = {2012-12-03},
	journal = {Annual Review of Psychology},
	author = {Birnbaum, Michael H.},
	year = {2004},
	note = {{PMID:} 14744235},
	pages = {803--832},
	file = {Full Text PDF:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/8MVV7CGI/Birnbaum - 2004 - Human Research and Data Collection via the Interne.pdf:application/pdf}
}

@article{reips_standards_2002,
	title = {Standards for Internet-Based Experimenting},
	volume = {49},
	issn = {1618-3169},
	url = {http://www.psycontent.com/content/e8l1777212686570/},
	doi = {10.1026//1618-3169.49.4.243},
	number = {4},
	urldate = {2012-12-03},
	journal = {Experimental Psychology (formerly {"Zeitschrift} für Experimentelle Psychologie")},
	author = {Reips, Ulf-Dietrich},
	month = oct,
	year = {2002},
	pages = {243--256},
	file = {ulf27.pdf:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/TEZ8Q7S9/ulf27.pdf:application/pdf;Untitled Attachment:/home/richard/.zotero/zotero/3bo0qlff.default/zotero/storage/ZEP3NWU4/Reips - 2002 - Standards for Internet-Based Experimenting.html:text/html}
}